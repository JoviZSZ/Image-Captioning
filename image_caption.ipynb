{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "from solver import *\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. create input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "with gzip.open('dataset_coco.json.gz', 'rb') as f_in:\n",
    "    with open('dataset_coco.json', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import create_input_files\n",
    "\n",
    "\n",
    "# Create input files (along with word map)\n",
    "create_input_files(dataset='coco',\n",
    "                   karpathy_json_path='./dataset_coco.json',\n",
    "                   image_folder='/datasets/COCO-2015/',\n",
    "                   captions_per_image=5,\n",
    "                   min_word_freq=5,\n",
    "                   output_folder='./inputData/',\n",
    "                   max_len=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "data_folder = './inputData/'  # folder with data files saved by create_input_files.py\n",
    "data_name = 'coco_5_cap_per_img_5_min_word_freq'  # base name shared by data files\n",
    "\n",
    "# Read word map\n",
    "word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n",
    "with open(word_map_file, 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "benchmark = False # if GPU is rtx2080, else True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  NIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "embed_encoder_dim = 512  # dimension of word embeddings\n",
    "hidden_dim = 512  # dimension of decoder RNN\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 vgg16 and NIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "\n",
    "decoder = DecoderWithoutAttention(image_output_dim = encoder.output_dim, hidden_dim = hidden_dim, \n",
    "                                  vocab_size =len(word_map), embed_encoder_dim=embed_encoder_dim, \n",
    "                                  device = device)\n",
    "checkpoint = None\n",
    "# checkpoint = 'BEST_checkpoint_vgg16_NIC_coco_5_cap_per_img_5_min_word_freq.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backprop_deep(encoder, decoder, data_folder, data_name, word_map, \n",
    "              epochs = 120, decoder_lr = 4e-4 , checkpoint = checkpoint, device = device, benchmark = benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 densenet161 and NIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder('densenet161')\n",
    "\n",
    "decoder = DecoderWithoutAttention(image_output_dim = encoder.output_dim,hidden_dim = hidden_dim, vocab_size =len(word_map),\n",
    "                                      embed_encoder_dim=embed_encoder_dim, device = device)\n",
    "checkpoint = None\n",
    "# checkpoint = 'BEST_checkpoint_densenet161_NIC_coco_5_cap_per_img_5_min_word_freq.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backprop_deep(encoder, decoder, data_folder, data_name, word_map, \n",
    "              epochs = 120, decoder_lr = 4e-4 , checkpoint = checkpoint, device = device, benchmark = benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3  resnet101 and NIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder('resnet101')\n",
    "\n",
    "decoder = DecoderWithoutAttention(image_output_dim = encoder.output_dim,hidden_dim = hidden_dim, vocab_size =len(word_map),\n",
    "                                      embed_encoder_dim=embed_encoder_dim, device = device)\n",
    "checkpoint = None\n",
    "# checkpoint = 'BEST_checkpoint_resnet101_NIC_coco_5_cap_per_img_5_min_word_freq.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "backprop_deep(encoder, decoder, data_folder, data_name, word_map, \n",
    "              epochs = 120, decoder_lr = 4e-4 , checkpoint = checkpoint, device = device, benchmark = benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "emb_dim = 512  # dimension of word embeddings\n",
    "attention_dim = 512  # dimension of attention linear layers\n",
    "hidden_dim = 512  # dimension of decoder RNN\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 vgg16 and NICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "\n",
    "decoder = DecoderWithAttention(attention_dim=attention_dim, embed_dim=emb_dim, hidden_dim=hidden_dim,\n",
    "                                   vocab_size=len(word_map), encoder_dim = encoder.output_dim, \n",
    "                                   dropout=dropout, device = device)\n",
    "checkpoint = None\n",
    "# checkpoint = 'BEST_checkpoint_vgg16_NICA_coco_5_cap_per_img_5_min_word_freq.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "backprop_deep(encoder, decoder, data_folder, data_name, word_map, \n",
    "              epochs = 120, decoder_lr = 4e-4 , checkpoint = checkpoint, device = device, benchmark = benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 densenet161 and NICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder('densenet161')\n",
    "\n",
    "decoder = DecoderWithAttention(attention_dim=attention_dim, embed_dim=emb_dim, hidden_dim=hidden_dim,\n",
    "                                   vocab_size=len(word_map), encoder_dim = encoder.output_dim, \n",
    "                                   dropout=dropout, device = device)\n",
    "checkpoint = None\n",
    "checkpoint = 'BEST_checkpoint_densenet161_NICA_coco_5_cap_per_img_5_min_word_freq.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "backprop_deep(encoder, decoder, data_folder, data_name, word_map, \n",
    "              epochs = 120, decoder_lr = 4e-4 , checkpoint = checkpoint, device = device, benchmark = benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3  resnet101 and NICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder('resnet101')\n",
    "\n",
    "decoder = DecoderWithAttention(attention_dim=attention_dim, embed_dim=emb_dim, hidden_dim=hidden_dim,\n",
    "                                   vocab_size=len(word_map), encoder_dim = encoder.output_dim, \n",
    "                                   dropout=dropout, device = device)\n",
    "checkpoint = None\n",
    "checkpoint = 'BEST_checkpoint_resnet101_NICA_coco_5_cap_per_img_5_min_word_freq.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "backprop_deep(encoder, decoder, data_folder, data_name, word_map, \n",
    "              epochs = 120, decoder_lr = 4e-4 , checkpoint = checkpoint, device = device, benchmark = benchmark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
